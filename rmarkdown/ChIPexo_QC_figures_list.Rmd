---
title: "ChIPexo QC figures"
author: "Rene Welch"
output: html_document
---

## Outline and ideas

The objective of the project was to develop a quality control pipeline for ChIPexo data. Therefore we want to:

1. Why did we decided to make a pipeline specific for ChIPexo, how does the current quality guidelines for ChIPseq behave in ChIPexo. Here we are going to show that current guidelines for ChIPseq are not enough for ChIPexo, and that our ideas are useful to asses the quality of this datasets.

    a. Diagram of how the pipeline works, rough explanation of biases and effects that are being measured
    b. Comparison of all datasets under current quality measures and comparison with the measures for the respective chipseq datasets. For the case of strand cross correlation it may be necessary to emphasize the absence of input reads for chipexo, which makes measures as RSC and NSC unavailable.
    
2. Show how the pipeline works. The first part is to explain what do we want to detect and why, then we need to show how are we detecting those and finally how did we evaluated that we are effectively finding or illustrating those effects

    a. Biases that we are detecting with the pipeline
    b. Determine good vs bad datasets, by comparing respect to a gold standard.
    c. 

## About ChIPexo data in general

1. Show how does it compare respect to chipseq (PET) and (SET)

    a. Compare without model, the tagcount scatter plot, forward strand ratio density, etc. This section analysis may be done with the construction of bins
    b. Compare with model, i.e. resolution, sensitivity and saturation analyses. The last part may link with experimental design issues

2. Show how does the biases of ChIPseq data are behaving in ChIPexo 

    a. This part may be GC and mappability plots. We have the case for CTCF which show that this quantities behave in the same fashion as the chip seq case.
    
## Algorithmic issues... 

I haven't paid to much attention to this, are we going to make comparisons with more datasets or only use the one that we have ?





3. We want to asses experimental design considerations by comparing all protocols against a gold standard set